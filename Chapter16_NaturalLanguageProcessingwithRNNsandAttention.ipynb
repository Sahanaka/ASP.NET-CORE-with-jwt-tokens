{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter16_NaturalLanguageProcessingwithRNNsandAttention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOiY4N+PoHT/Y0ubj04pJQS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sahanaka/ASP.NET-CORE-with-jwt-tokens/blob/master/Chapter16_NaturalLanguageProcessingwithRNNsandAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdzeW7WNpE1w"
      },
      "source": [
        "# Usual imports and the plotting functions\n",
        "import sys\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmPN6MZhQ9an",
        "outputId": "cf77dbeb-032e-4459-de9c-eb8994fd6bf7"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "n_steps = 5\n",
        "dataset = tf.data.Dataset.from_tensor_slices(tf.range(15))\n",
        "dataset = dataset.window(n_steps, shift=2, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(n_steps))\n",
        "dataset = dataset.shuffle(10).map(lambda window: (window[:-1], window[1:]))\n",
        "dataset = dataset.batch(3).prefetch(1)\n",
        "for index, (X_batch, Y_batch) in enumerate(dataset):\n",
        "    print(\"_\" * 20, \"Batch\", index, \"\\nX_batch\")\n",
        "    print(X_batch.numpy())\n",
        "    print(\"=\" * 5, \"\\nY_batch\")\n",
        "    print(Y_batch.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____________________ Batch 0 \n",
            "X_batch\n",
            "[[6 7 8 9]\n",
            " [2 3 4 5]\n",
            " [4 5 6 7]]\n",
            "===== \n",
            "Y_batch\n",
            "[[ 7  8  9 10]\n",
            " [ 3  4  5  6]\n",
            " [ 5  6  7  8]]\n",
            "____________________ Batch 1 \n",
            "X_batch\n",
            "[[ 0  1  2  3]\n",
            " [ 8  9 10 11]\n",
            " [10 11 12 13]]\n",
            "===== \n",
            "Y_batch\n",
            "[[ 1  2  3  4]\n",
            " [ 9 10 11 12]\n",
            " [11 12 13 14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kz5kFgApwRN"
      },
      "source": [
        "# **Char RNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Lc7rWURp3Lt"
      },
      "source": [
        "## **Loading the Data and Preparing the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NvbA29_pqjQ",
        "outputId": "300e0f79-3c3a-4992-b090-ee255c9862b2"
      },
      "source": [
        "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\" # Dataset url\n",
        "filepath = keras.utils.get_file('shakespeare.txt', shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy7M7TP2q9DH",
        "outputId": "1cab6a0d-69d0-444d-bc45-4686d262fc94"
      },
      "source": [
        "print(shakespeare_text[:200]) # Contains a dialog. Change the number and run "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPu4XOv1rt9W"
      },
      "source": [
        "Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIen_IeurBrs"
      },
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True) # Using the keras tokenizer; char_level true gives character level tokenization. Default is the word tokenization\n",
        "tokenizer.fit_on_texts(shakespeare_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc2EL0EEsLmo",
        "outputId": "e5c30b42-c463-412e-95c7-60654b08df05"
      },
      "source": [
        "tokenizer.texts_to_sequences([\"First\"]) # Gets the id's"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20, 6, 9, 8, 3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdmRWAkZuObP",
        "outputId": "dbeda37a-e28c-4d97-e54a-d1078c0322ff"
      },
      "source": [
        "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]]) # Gets the characters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f i r s t']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ssSNQ2luZo1"
      },
      "source": [
        "max_id = len(tokenizer.word_index) # Number of distinct characters\n",
        "dataset_size = tokenizer.document_count # Total number of characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA3Tzs3Qu2WF"
      },
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1 # -1 to get the IDs from 0\n",
        "train_size = dataset_size * 90 // 100 # Train split\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUWGK5cRvUuJ"
      },
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = input shifted 1 character ahead \n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True) # Shift=1 to get the largest possbile set\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nGSN3ZXMbDD",
        "outputId": "ba2d1a9c-e3f2-4bcd-8ee8-affc3239a90a"
      },
      "source": [
        "# Flatten the dataset\n",
        "dataset = dataset.map(lambda window: window.batch(window_length)) # transform the nested dataset into a flat list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MapDataset shapes: DatasetSpec(TensorSpec(shape=(None, None), dtype=tf.int64, name=None), TensorShape([])), types: DatasetSpec(TensorSpec(shape=(None, None), dtype=tf.int64, name=None), TensorShape([]))>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeFi6VvcOui7"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2aI7HKEPbKR"
      },
      "source": [
        "# Shuffle the dataset\n",
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "# dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnWOnTaOP3Ho"
      },
      "source": [
        "# One hot encode the characters\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGWMw46qQarv"
      },
      "source": [
        "dataset = dataset.prefetch(1) # PRefetching"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulRem41XRa6B",
        "outputId": "99cd016f-f1a9-42c2-a4f6-1345a6ee281a"
      },
      "source": [
        "for X_batch, Y_batch in dataset.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 4, 39) (3, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9ZQNS_vWy3q"
      },
      "source": [
        "## **Exercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXL7dD2GXLpK"
      },
      "source": [
        "Exercise: Train an Encoder–Decoder model that can convert a date string from one format to another (e.g., from \"April 22, 2019\" to \"2019-04-22\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgrpOV4xXSia"
      },
      "source": [
        "**First we have to make the dataset. Let's create a random dataset in the following time range**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isZIfwe8W4sT"
      },
      "source": [
        "from datetime import date"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdQeIpqlXkiF"
      },
      "source": [
        "# Creating a dataset of inputs and targets\n",
        "MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
        "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
        "\n",
        "def random_dates(n_dates):\n",
        "  # MIN MAX dates\n",
        "  min_date = date(1000, 1, 1).toordinal()\n",
        "  max_date = date(9999, 12, 31).toordinal()\n",
        "\n",
        "  # Creating random ordinals in the range\n",
        "  ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
        "  \n",
        "  # Convert to dates\n",
        "  dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
        "  x = [MONTHS[dt.month - 1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n",
        "  y = [dt.isoformat() for dt in dates]\n",
        "  return x, y\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX6DGQXeYZ3f"
      },
      "source": [
        "X, y = random_dates(23)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8b5LXa0YcOt",
        "outputId": "b698e95b-4059-418f-e0dc-72a97cee3697"
      },
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['September 20, 7075', 'May 15, 8579', 'January 11, 7103', 'June 01, 7451', 'July 29, 5634', 'November 27, 1301', 'August 23, 3004', 'December 26, 9762', 'October 29, 7117', 'June 01, 9479', 'July 13, 5298', 'October 11, 6484', 'June 20, 4110', 'November 06, 9240', 'July 01, 7221', 'October 06, 4394', 'August 06, 1761', 'April 23, 6854', 'October 10, 1901', 'March 08, 9790', 'April 15, 3155', 'March 07, 4752', 'August 02, 5837']\n",
            "['7075-09-20', '8579-05-15', '7103-01-11', '7451-06-01', '5634-07-29', '1301-11-27', '3004-08-23', '9762-12-26', '7117-10-29', '9479-06-01', '5298-07-13', '6484-10-11', '4110-06-20', '9240-11-06', '7221-07-01', '4394-10-06', '1761-08-06', '6854-04-23', '1901-10-10', '9790-03-08', '3155-04-15', '4752-03-07', '5837-08-02']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV1hjsWbbasq"
      },
      "source": [
        "**Let's find all possible inputs chars and output chars**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lRdB_NIIbaYq",
        "outputId": "1650e1ff-e489-4aea-890c-a93499e16775"
      },
      "source": [
        "INPUT_CHARS = \"\".join(sorted(set(\"\".join(MONTHS) + \"0123456789, \")))\n",
        "INPUT_CHARS"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' ,0123456789ADFJMNOSabceghilmnoprstuvy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UywiSKM_ao7R"
      },
      "source": [
        "OUTPUT_CHARS = \"0123456789-\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYhFLV-gcJuH"
      },
      "source": [
        "Function to convert to list of characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIE3FgLrbnP9"
      },
      "source": [
        "def date_str_to_ids(date_str, chars=INPUT_CHARS):\n",
        "    return [chars.index(c) for c in date_str]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFWHG6-5cIfj"
      },
      "source": [
        "def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n",
        "    X_ids = [date_str_to_ids(dt, chars) for dt in date_strs]\n",
        "    X = tf.ragged.constant(X_ids, ragged_rank=1)\n",
        "    return (X + 1).to_tensor() # using 0 as the padding token ID\n",
        "\n",
        "def create_dataset(n_dates):\n",
        "    x, y = random_dates(n_dates)\n",
        "    return prepare_date_strs(x, INPUT_CHARS), prepare_date_strs(y, OUTPUT_CHARS)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr_ncIo4clKy"
      },
      "source": [
        "# Create train, validation and test sets\n",
        "np.random.seed(42)\n",
        "\n",
        "# All are tensors\n",
        "X_train, Y_train = create_dataset(10000)\n",
        "X_valid, Y_valid = create_dataset(2000)\n",
        "X_test, Y_test = create_dataset(2000)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-KQ6iNooQHz"
      },
      "source": [
        "## **v1: A very basic seq2seq model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gAIVaO7offV"
      },
      "source": [
        "**We feed in the input sequence, which first goes through the encoder (an embedding layer followed by a single LSTM layer), which outputs a vector, then it goes through a decoder (a single LSTM layer, followed by a dense output layer), which outputs a sequence of vectors, each representing the estimated probabilities for all possible output character.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn1hc5RepH8U"
      },
      "source": [
        "embedding_size = 32\n",
        "max_output_length = Y_train.shape[1]\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju7-Qllrcroz"
      },
      "source": [
        "# Encoder\n",
        "encoder = keras.models.Sequential([\n",
        "                                   keras.layers.Embedding(input_dim=len(INPUT_CHARS) + 1,\n",
        "                                                          output_dim=embedding_size,\n",
        "                                                          input_shape=[None]),\n",
        "                                   keras.layers.LSTM(128)\n",
        "])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaKJl9e7dfUS"
      },
      "source": [
        "# Decoder\n",
        "decoder = keras.models.Sequential([\n",
        "                                   keras.layers.LSTM(128, return_sequences=True),\n",
        "                                   keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation=\"softmax\") # Output layer\n",
        "])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU6KZ-2IsNIC"
      },
      "source": [
        "# Final model\n",
        "model = keras.models.Sequential([\n",
        "    encoder,\n",
        "    keras.layers.RepeatVector(max_output_length),\n",
        "    decoder\n",
        "])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23qywh7zslIC"
      },
      "source": [
        "model.compile(optimizer=\"Nadam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qABgFdWuogV",
        "outputId": "986a680f-86b4-421d-d57e-36cb7c5fe5c0"
      },
      "source": [
        "history = model.fit(X_train, Y_train, epochs=20,\n",
        "                    validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 13s 11ms/step - loss: 1.7910 - accuracy: 0.3587 - val_loss: 1.3599 - val_accuracy: 0.4924\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3234 - accuracy: 0.5250 - val_loss: 1.1575 - val_accuracy: 0.5795\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0256 - accuracy: 0.6289 - val_loss: 0.9909 - val_accuracy: 0.6309\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8921 - accuracy: 0.6776 - val_loss: 0.7374 - val_accuracy: 0.7218\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6358 - accuracy: 0.7559 - val_loss: 0.5939 - val_accuracy: 0.7675\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5727 - accuracy: 0.7886 - val_loss: 0.4186 - val_accuracy: 0.8332\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5183 - accuracy: 0.8140 - val_loss: 0.5222 - val_accuracy: 0.8088\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3224 - accuracy: 0.8842 - val_loss: 0.2504 - val_accuracy: 0.9100\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5986 - accuracy: 0.8135 - val_loss: 0.3554 - val_accuracy: 0.8933\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2477 - accuracy: 0.9320 - val_loss: 0.1865 - val_accuracy: 0.9511\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2518 - accuracy: 0.9321 - val_loss: 0.2153 - val_accuracy: 0.9435\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1191 - accuracy: 0.9777 - val_loss: 0.0806 - val_accuracy: 0.9880\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0560 - accuracy: 0.9937 - val_loss: 0.0447 - val_accuracy: 0.9962\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0321 - accuracy: 0.9976 - val_loss: 0.0283 - val_accuracy: 0.9977\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0200 - accuracy: 0.9992 - val_loss: 0.0189 - val_accuracy: 0.9988\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0130 - accuracy: 0.9998 - val_loss: 0.0131 - val_accuracy: 0.9995\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9997\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9999\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9999\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNbIUv7muzLb"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}